{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create a Google Colab Account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Completed.** *Account: thomas.sanger92@gmail.com*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Dataset and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive to access data\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Import data manipulation and visualization libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define paths to image and label data\n",
    "images_path = '/content/drive/MyDrive/ColabNotebooks/images.npy'\n",
    "labels_path = '/content/drive/MyDrive/ColabNotebooks/Labels.csv'\n",
    "\n",
    "# Check if the data files exist\n",
    "print(os.path.exists(images_path))  # Check if images.npy exists\n",
    "print(os.path.exists(labels_path))  # Check if Labels.csv exists\n",
    "\n",
    "# Load the image and label data\n",
    "images = np.load(images_path) # image data\n",
    "labels = pd.read_csv(labels_path) # label data\n",
    "\n",
    "# Explore the dataset: Print column names, shapes, class distribution\n",
    "print(labels.columns) # Shows the names of the columns in the labels DataFrame\n",
    "print(f\"Images shape: {images.shape}\") # Prints the dimensions of the image data\n",
    "print(f\"Labels shape: {labels.shape}\") # Prints the dimensions of the label data\n",
    "print(labels['Label'].value_counts(normalize=True)) # Shows the distribution of plant species\n",
    "\n",
    "# Visualize sample images: Display the first few images from the dataset\n",
    "unique_labels = labels['Label'].unique() # Gets the unique plant species labels\n",
    "plt.figure(figsize=(12, 12)) # Sets the size of the figure for the plot\n",
    "for i, label in enumerate(unique_labels[:12], 1): # Loops through the first 12 unique labels\n",
    "    plt.subplot(4, 3, i) # Creates a subplot within the figure\n",
    "    idx = labels[labels['Label'] == label].index[0] # Finds the index of the first image with the current label\n",
    "    plt.imshow(images[idx]) # Displays the image\n",
    "    plt.title(label) # Sets the title of the subplot to the plant species label\n",
    "    plt.axis('off') # Hides the axes\n",
    "plt.tight_layout() # Adjusts the spacing between subplots\n",
    "plt.show() # Displays the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Perform EDA on the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Plot: Visualize the distribution of plant species using a count plot\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6)) # Sets the figure size\n",
    "sns.countplot(data=labels, x='Label') # Creates a count plot using Seaborn\n",
    "plt.title(\"Class Distribution\") # Sets the title of the plot\n",
    "plt.xticks(rotation=45) # Rotates x-axis labels for better readability\n",
    "plt.show() # Displays the plot\n",
    "\n",
    "# Plot the first image of each species\n",
    "plt.figure(figsize=(12, 12)) # Sets the figure size\n",
    "for i, label in enumerate(unique_labels[:12], 1): # Loops through the first 12 unique labels\n",
    "    plt.subplot(4, 3, i) # Creates a subplot within the figure\n",
    "    idx = labels[labels['Label'] == label].index[0] # Finds the index of the first image with the current label\n",
    "    plt.imshow(images[idx]) # Displays the image\n",
    "    plt.title(label) # Sets the title of the subplot to the plant species label\n",
    "    plt.axis('off') # Hides the axes\n",
    "plt.tight_layout() # Adjusts the spacing between subplots\n",
    "plt.show() # Displays the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Illustrate Insights from EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first insight into the Exploratory Data Analysis is that they are all\n",
    "planted with the same mulch/pubble background. Secondly, it seems that the\n",
    "dataset is relatively balanced, with each weed species having a similar number\n",
    "of samples. Thirdly, upon visual inspection, the plant species show signs of\n",
    "distict visual characteristics making them easily identifiable. Lastly, no\n",
    "apparent missing or corrrupted images were found in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from skimage.filters import gaussian\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Apply Gaussian Blurring to remove noise from images\n",
    "blurred_images = np.array([gaussian(image, sigma=1, channel_axis=-1) for image in images])\n",
    "\n",
    "# Clip pixel values to the range [0, 1] for normalization\n",
    "blurred_images = np.clip(blurred_images, 0, 1)\n",
    "\n",
    "# Normalize images: No need to divide by 255 as they are already clipped to [0,1]\n",
    "normalized_images = blurred_images\n",
    "\n",
    "# Visualize the effect of preprocessing: Compare original and preprocessed images\n",
    "plt.figure(figsize=(10, 5)) # Set figure size for the plot\n",
    "plt.subplot(1, 2, 1) # Create a subplot for the original image\n",
    "plt.imshow(images[0]) # Display the first original image\n",
    "plt.title(\"Original Image\") # Set title for the original image subplot\n",
    "plt.axis('off') # Hide axes for the original image\n",
    "\n",
    "plt.subplot(1, 2, 2) # Create a subplot for the preprocessed image\n",
    "plt.imshow(normalized_images[0]) # Display the first preprocessed image\n",
    "plt.title(\"Preprocessed Image\") # Set title for the preprocessed image subplot\n",
    "plt.axis('off') # Hide axes for the preprocessed image\n",
    "\n",
    "# Adjust subplot spacing and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Split data into training and testing sets using stratified sampling\n",
    "# 'stratify' ensures that the class distribution is maintained in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    normalized_images, labels['Label'], test_size=0.2, stratify=labels['Label'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Make Data Compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for label encoding and one-hot encoding\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Create LabelEncoder and OneHotEncoder instances\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Encode labels using LabelEncoder and OneHotEncoder\n",
    "# Fit_transform on training data, transform on testing data\n",
    "y_train_encoded = onehot_encoder.fit_transform(label_encoder.fit_transform(y_train).reshape(-1, 1))\n",
    "y_test_encoded = onehot_encoder.transform(label_encoder.transform(y_test).reshape(-1, 1))\n",
    "\n",
    "# Reshape image data to be compatible with CNN input shape (samples, height, width, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], images.shape[1], images.shape[2], images.shape[3])\n",
    "X_test = X_test.reshape(X_test.shape[0], images.shape[1], images.shape[2], images.shape[3])\n",
    "\n",
    "# Print shapes to verify data compatibility\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train_encoded shape: {y_train_encoded.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test_encoded shape: {y_test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary layers for building the CNN model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "\n",
    "# Define the input shape for the model\n",
    "input_tensor = Input(shape=(images.shape[1], images.shape[2], images.shape[3]))\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "model.add(input_tensor)  # Add the Input layer directly to the Sequential model\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))  # Add a convolutional layer with 32 filters\n",
    "model.add(MaxPooling2D((2, 2))) # Add a max pooling layer\n",
    "model.add(Dropout(0.25)) # Add dropout for regularization\n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) # Add another convolutional layer with 64 filters\n",
    "model.add(MaxPooling2D((2, 2))) # Add another max pooling layer\n",
    "model.add(Dropout(0.25)) # Add dropout for regularization\n",
    "model.add(Flatten()) # Flatten the output for the dense layers\n",
    "model.add(Dense(128, activation='relu')) # Add a dense layer with 128 units\n",
    "model.add(Dropout(0.5)) # Add dropout for regularization\n",
    "model.add(Dense(12, activation='softmax'))  # Add the output layer with 12 units (for 12 classes)\n",
    "\n",
    "# Compile the model with optimizer, loss function, and metrics\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training data and validate on the testing data\n",
    "history = model.fit(X_train, y_train_encoded,\n",
    "                    validation_data=(X_test, y_test_encoded),\n",
    "                    epochs=20, batch_size=32)\n",
    "                    # epochs: number of times the model sees the entire dataset\n",
    "                    # batch_size: number of samples processed before weights are updated\n",
    "\n",
    "# Plot the training and validation accuracy over epochs\n",
    "plt.figure(figsize=(12, 6)) # Set figure size\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy') # Plot training accuracy\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy') # Plot validation accuracy\n",
    "plt.legend() # Show legend\n",
    "plt.title(\"Model Accuracy\") # Set title\n",
    "plt.xlabel(\"Epochs\") # Set x-axis label\n",
    "plt.ylabel(\"Accuracy\") # Set y-axis label\n",
    "plt.show() # Display the plot\n",
    "\n",
    "# Plot the training and validation loss over epochs\n",
    "plt.figure(figsize=(12, 6)) # Set figure size\n",
    "plt.plot(history.history['loss'], label='Training Loss') # Plot training loss\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss') # Plot validation loss\n",
    "plt.legend() # Show legend\n",
    "plt.title(\"Model Loss\") # Set title\n",
    "plt.xlabel(\"Epochs\") # Set x-axis label\n",
    "plt.ylabel(\"Loss\") # Set y-axis label\n",
    "plt.show() # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test) # Get predicted probabilities for each class\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) # Convert probabilities to class predictions\n",
    "y_test_classes = np.argmax(y_test_encoded, axis=1) # Get true class labels\n",
    "\n",
    "# Generate and print the classification report\n",
    "# Includes precision, recall, F1-score, and support for each class\n",
    "print(classification_report(y_test_classes, y_pred_classes,\n",
    "                            target_names=label_encoder.classes_,\n",
    "                            zero_division=0))\n",
    "                            # zero_division handles cases where a class has no predicted samples\n",
    "\n",
    "# Generate and plot the confusion matrix\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes) # Create confusion matrix\n",
    "plt.figure(figsize=(12, 10)) # Set figure size\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_,\n",
    "            cmap='Blues')\n",
    "            # annot: display values in cells\n",
    "            # fmt: format of displayed values\n",
    "            # xticklabels, yticklabels: class names for axes\n",
    "            # cmap: color map for the heatmap\n",
    "\n",
    "plt.title(\"Confusion Matrix\") # Set title\n",
    "plt.xlabel(\"Predicted\") # Set x-axis label\n",
    "plt.ylabel(\"True\") # Set y-axis label\n",
    "plt.show() # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Conclusions and Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was able to successfully classify plant seedlings into 12 distinct\n",
    "species with above average accuracy. Both the training and validation\n",
    "performance demonstrated that the model effectively learned the visual\n",
    "features associated with each plant category. The confusion matrix revealed\n",
    "that most species were correctly classified, though some species with visually\n",
    "similar characteristics experienced higher misclassification rates. This\n",
    "suggests the model could benefit from additional data or more advanced\n",
    "techniques to better differentiate between visually similar species.\n",
    "\n",
    "To further improve the model, strategies such as data augmentation, which\n",
    "enhances the diversity of training samples, could be implemented. Transfer\n",
    "learning using pre-trained models might also improve classification\n",
    "performance, particularly for more challenging species. Additionally,\n",
    "fine-tuning hyperparameters or increasing the dataset size could enhance the\n",
    "modelâ€™s generalization. Overall, this project highlights the potential of\n",
    "deep learning in agriculture to automate tasks such as plant identification,\n",
    "paving the way for more efficient and sustainable farming practices."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
